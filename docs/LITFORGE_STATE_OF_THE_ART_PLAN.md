# LitForge: State-of-the-Art Architecture and Enhancement Plan

**Version**: 2.0  
**Date**: January 2025  
**Vision**: The definitive scientific literature backbone for AI agents and researchers

---

## Executive Summary

This document presents a comprehensive re-evaluation of LitForge's architecture against state-of-the-art systems (PaperQA2, GPT-Researcher, Semantic Scholar, Elicit) and proposes enhancements to make LitForge a **truly professional, production-ready** library suitable for:

1. **Standalone use** - Researchers using LitForge directly
2. **Library integration** - Import into any Python project
3. **Agentic systems** - Multi-agent orchestration (CrewAI, AutoGen, LangGraph)
4. **MCP tool** - Claude and AI assistant integration

**Key Insight**: Current LitForge has the right *structure* but lacks the *depth* needed for state-of-the-art performance. This plan addresses that gap.

---

## Part 1: State-of-the-Art Competitive Analysis

### 1.1 Leading Systems Comparison

| Feature | PaperQA2 | GPT-Researcher | Elicit | Semantic Scholar | **LitForge (Goal)** |
|---------|----------|----------------|--------|------------------|---------------------|
| **Search Sources** | S2, CrossRef | Web + Arxiv | Multiple | Own DB | âœ… 6+ sources |
| **PDF Retrieval** | Unpaywall | Web scraping | Limited | Direct links | âœ… Waterfall strategy |
| **Full-text Extraction** | Advanced | Basic | Unknown | N/A | âœ… Section-aware |
| **RAG Q&A** | Superhuman | Report-style | Good | N/A | âœ… Evidence-based |
| **Citation Networks** | Basic | None | Basic | Excellent | âœ… Advanced graphs |
| **Streaming** | âœ… | âœ… | âœ… | N/A | âœ… Real-time |
| **Agentic** | âœ… | âœ… | âŒ | âŒ | âœ… Multi-agent |
| **Evidence Grounding** | âœ… | Partial | âœ… | N/A | âœ… Full provenance |
| **Hallucination Prevention** | âœ… | Partial | âœ… | N/A | âœ… Built-in |
| **Local LLM Support** | âœ… | Partial | âŒ | N/A | âœ… Ollama, vLLM |
| **Cost (per query)** | ~$0.40 | ~$0.30 | $$ | Free | âœ… $0-0.10 |

### 1.2 What Makes PaperQA2 "Superhuman"

PaperQA2 achieved #1 on DeepResearchGym with these techniques:

1. **Evidence-based answering** - Every claim linked to source text
2. **Iterative refinement** - Search â†’ Retrieve â†’ Answer â†’ Verify â†’ Refine
3. **Citation context** - Uses surrounding sentences, not just snippets
4. **Contradiction detection** - Identifies conflicting evidence
5. **Confidence scoring** - Indicates answer certainty
6. **Multi-paper synthesis** - Combines evidence across papers

**LitForge must match or exceed these capabilities.**

---

## Part 2: Current Gaps - Deep Analysis

### 2.1 Architecture Gaps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CURRENT vs REQUIRED                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  CURRENT ARCHITECTURE                 REQUIRED ARCHITECTURE              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚                                                                          â”‚
â”‚  Simple API (sync only)               Async-first with sync wrapper      â”‚
â”‚  Single source per query              Parallel multi-source fusion       â”‚
â”‚  Basic keyword search                 Hybrid search (dense + sparse)     â”‚
â”‚  No reranking                         Cross-encoder reranking            â”‚
â”‚  Simple Paper model                   Rich Document model with chunks    â”‚
â”‚  No streaming                         Full streaming support             â”‚
â”‚  Basic error handling                 Circuit breaker + retry            â”‚
â”‚  No provenance tracking               Full evidence trail                â”‚
â”‚  Single-turn Q&A only                 Multi-turn with memory             â”‚
â”‚  No agent capabilities                Full agentic reasoning             â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Missing Critical Features

| Category | Feature | Priority | Effort |
|----------|---------|----------|--------|
| **Search** | Hybrid search (BM25 + semantic) | â­â­â­ | Medium |
| **Search** | Query expansion/reformulation | â­â­â­ | Medium |
| **Search** | Cross-encoder reranking | â­â­â­ | Medium |
| **Retrieval** | Waterfall PDF strategy | â­â­â­ | High |
| **Retrieval** | Smart caching with TTL | â­â­ | Low |
| **Extraction** | Section-aware parsing | â­â­â­ | High |
| **Extraction** | Table extraction | â­â­ | High |
| **Extraction** | Figure caption extraction | â­â­ | Medium |
| **RAG** | Chunking strategies | â­â­â­ | Medium |
| **RAG** | Evidence extraction | â­â­â­ | High |
| **RAG** | Citation grounding | â­â­â­ | High |
| **RAG** | Contradiction detection | â­â­ | High |
| **RAG** | Confidence scoring | â­â­ | Medium |
| **Agent** | Research planning | â­â­â­ | High |
| **Agent** | Iterative refinement | â­â­â­ | High |
| **Agent** | Tool orchestration | â­â­â­ | Medium |
| **Network** | Influence metrics | â­â­ | Medium |
| **Network** | Concept clustering | â­â­ | High |
| **Network** | Trend detection | â­â­ | High |
| **Output** | Streaming responses | â­â­â­ | Medium |
| **Output** | Export (BibTeX, RIS) | â­â­ | Low |
| **Output** | Visualization | â­â­ | Medium |

---

## Part 3: Enhanced Architecture Design

### 3.1 Core Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LitForge v2.0 Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         API LAYER                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚ â”‚
â”‚  â”‚  â”‚ Simple   â”‚  â”‚  Forge   â”‚  â”‚  REST    â”‚  â”‚   MCP    â”‚            â”‚ â”‚
â”‚  â”‚  â”‚   API    â”‚  â”‚  Class   â”‚  â”‚   API    â”‚  â”‚  Server  â”‚            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      ORCHESTRATION LAYER                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   Research Agent    â”‚  â”‚          Task Planner               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Plan â†’ Search â”‚  â”‚  â”‚  â”‚ Decompose â†’ Schedule â†’ Trackâ”‚   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â†’ Retrieve â†’  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â†’ Analyze â†’   â”‚  â”‚  â”‚                                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ â†’ Synthesize  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚    Conversation Memory      â”‚   â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        SERVICE LAYER                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚  â”‚ Discovery  â”‚ â”‚ Retrieval  â”‚ â”‚ Knowledge  â”‚ â”‚   Q&A      â”‚       â”‚ â”‚
â”‚  â”‚  â”‚  Service   â”‚ â”‚  Service   â”‚ â”‚  Service   â”‚ â”‚  Service   â”‚       â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚  â”‚  Citation  â”‚ â”‚  Concept   â”‚ â”‚  Synthesis â”‚ â”‚   Export   â”‚       â”‚ â”‚
â”‚  â”‚  â”‚  Service   â”‚ â”‚  Service   â”‚ â”‚  Service   â”‚ â”‚  Service   â”‚       â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        CORE LAYER                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚  â”‚  Clients   â”‚ â”‚ Processors â”‚ â”‚  Stores    â”‚ â”‚   LLM      â”‚       â”‚ â”‚
â”‚  â”‚  â”‚ (6 APIs)   â”‚ â”‚ (PDF/Text) â”‚ â”‚ (Vector)   â”‚ â”‚  Router    â”‚       â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ â”‚
â”‚  â”‚  â”‚ Embeddings â”‚ â”‚  Rankers   â”‚ â”‚   Cache    â”‚ â”‚  Metrics   â”‚       â”‚ â”‚
â”‚  â”‚  â”‚            â”‚ â”‚            â”‚ â”‚            â”‚ â”‚            â”‚       â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Data Flow for Research Query

```
User: "What are the latest advances in CRISPR delivery mechanisms?"
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                               â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Query Parser  â”‚               â”‚ Intent Router â”‚
           â”‚ - Entity NER  â”‚               â”‚ - Search/Q&A  â”‚
           â”‚ - Query expandâ”‚               â”‚ - Compare     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ - Summarize   â”‚
                    â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
           â”‚ Research Plan â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ - Steps       â”‚
           â”‚ - Dependenciesâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚OpenAlex â”‚ â”‚Semantic â”‚ â”‚ PubMed  â”‚  (Parallel search)
   â”‚ Search  â”‚ â”‚ Scholar â”‚ â”‚ Search  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Dedup &     â”‚
           â”‚   Merge       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Reranker     â”‚  (Cross-encoder)
           â”‚  (top-k)      â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Unpaywallâ”‚ â”‚  arXiv  â”‚ â”‚  CORE   â”‚  (PDF retrieval)
   â”‚   PDF   â”‚ â”‚   PDF   â”‚ â”‚   PDF   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ PDF Processor â”‚
           â”‚ - Extract     â”‚
           â”‚ - Section     â”‚
           â”‚ - Chunk       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Vector Index  â”‚
           â”‚ - Embed       â”‚
           â”‚ - Store       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ RAG Retrieval â”‚
           â”‚ - Hybrid      â”‚
           â”‚ - Rerank      â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ LLM Synthesis â”‚
           â”‚ - Answer      â”‚
           â”‚ - Citations   â”‚
           â”‚ - Confidence  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Evidence      â”‚
           â”‚ Verification  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
              Final Answer
           with Citations
```

---

## Part 4: New Components to Add

### 4.1 Research Agent (`src/litforge/agents/research_agent.py`)

**Purpose**: Autonomous multi-step research with planning and refinement

```python
class ResearchAgent:
    """
    Autonomous research agent that plans and executes literature research.
    
    Capabilities:
    - Decompose complex queries into sub-tasks
    - Search across multiple sources
    - Retrieve and process PDFs
    - Synthesize findings with citations
    - Iteratively refine answers
    """
    
    async def research(
        self,
        query: str,
        *,
        depth: Literal["quick", "standard", "deep"] = "standard",
        max_papers: int = 20,
        require_fulltext: bool = False,
    ) -> ResearchResult:
        """
        Conduct autonomous research on a topic.
        
        Args:
            query: Research question or topic
            depth: How deep to research
                - quick: Top 5 papers, abstracts only
                - standard: Top 20 papers, full text when available
                - deep: Comprehensive search, all available full text
            max_papers: Maximum papers to analyze
            require_fulltext: Only include papers with full text
            
        Returns:
            ResearchResult with answer, evidence, and sources
        """
```

### 4.2 Evidence Extractor (`src/litforge/processors/evidence.py`)

**Purpose**: Extract evidence passages with precise citations

```python
class EvidenceExtractor:
    """
    Extract and score evidence from documents.
    
    Features:
    - Claim-evidence matching
    - Relevance scoring
    - Contradiction detection
    - Context expansion
    """
    
    def extract_evidence(
        self,
        claim: str,
        documents: list[Document],
        *,
        top_k: int = 5,
        min_score: float = 0.5,
    ) -> list[Evidence]:
        """Extract evidence passages supporting or contradicting a claim."""
    
    def detect_contradictions(
        self,
        evidence: list[Evidence],
    ) -> list[Contradiction]:
        """Identify contradicting evidence from different sources."""
```

### 4.3 Concept Extractor (`src/litforge/processors/concepts.py`)

**Purpose**: Extract and organize scientific concepts

```python
class ConceptExtractor:
    """
    Extract scientific concepts and relationships from literature.
    
    Features:
    - Named entity recognition (chemicals, genes, diseases, etc.)
    - Relationship extraction
    - Concept clustering
    - Ontology mapping
    """
    
    def extract_concepts(
        self,
        text: str,
        domain: str = "general",
    ) -> list[Concept]:
        """Extract scientific concepts from text."""
    
    def build_concept_graph(
        self,
        papers: list[Publication],
    ) -> ConceptGraph:
        """Build a concept relationship graph from papers."""
```

### 4.4 Hybrid Retriever (`src/litforge/retrieval/hybrid.py`)

**Purpose**: Combine dense and sparse retrieval for best results

```python
class HybridRetriever:
    """
    Hybrid retrieval combining BM25 + dense embeddings.
    
    Based on research showing hybrid retrieval outperforms
    pure dense or sparse approaches.
    """
    
    def __init__(
        self,
        dense_weight: float = 0.7,
        sparse_weight: float = 0.3,
        reranker: CrossEncoderReranker | None = None,
    ):
        self.bm25 = BM25Index()
        self.dense = DenseIndex()
        self.reranker = reranker
    
    def search(
        self,
        query: str,
        top_k: int = 10,
    ) -> list[RetrievedChunk]:
        """Hybrid search with optional reranking."""
```

### 4.5 Streaming Handler (`src/litforge/streaming/handler.py`)

**Purpose**: Real-time streaming for all operations

```python
class StreamingHandler:
    """
    Handle streaming responses for all LitForge operations.
    
    Supports:
    - SSE (Server-Sent Events)
    - WebSocket
    - AsyncIterator
    """
    
    async def stream_research(
        self,
        query: str,
    ) -> AsyncIterator[ResearchEvent]:
        """
        Stream research progress and results.
        
        Yields:
            ResearchEvent objects:
            - PlanEvent: Research plan created
            - SearchEvent: Papers found
            - RetrievalEvent: PDF downloaded
            - ProcessingEvent: Document processed
            - EvidenceEvent: Evidence extracted
            - AnswerChunk: Partial answer text
            - CompleteEvent: Final result
        """
```

### 4.6 LLM Router (`src/litforge/llm/router.py`)

**Purpose**: Smart routing across LLM providers

```python
class LLMRouter:
    """
    Intelligent LLM routing with fallback and cost optimization.
    
    Supports:
    - Groq (free, fast)
    - OpenAI (quality)
    - Anthropic (reasoning)
    - Ollama (local)
    - vLLM (self-hosted)
    """
    
    def __init__(
        self,
        primary: str = "groq",
        fallback: list[str] = ["openai", "ollama"],
        cost_limit: float | None = None,
    ):
        pass
    
    async def complete(
        self,
        prompt: str,
        *,
        task: Literal["parse", "synthesize", "reason"] = "synthesize",
        stream: bool = False,
    ) -> str | AsyncIterator[str]:
        """Route to appropriate LLM based on task and availability."""
```

---

## Part 5: Enhanced Models

### 5.1 Document Model (extends Publication)

```python
@dataclass
class Document:
    """
    Rich document model with full-text and chunks.
    
    Extends Publication with:
    - Parsed sections
    - Text chunks for RAG
    - Extracted entities
    - Quality metrics
    """
    
    publication: Publication
    
    # Full text content
    full_text: str
    sections: dict[str, Section]  # intro, methods, results, discussion
    
    # Chunks for RAG
    chunks: list[DocumentChunk]
    chunk_embeddings: np.ndarray | None
    
    # Extracted content
    tables: list[Table]
    figures: list[Figure]
    equations: list[Equation]
    references: list[Reference]
    
    # Quality metrics
    extraction_quality: float  # 0-1 score
    has_ocr_errors: bool
    language: str
```

### 5.2 Evidence Model

```python
@dataclass
class Evidence:
    """
    Evidence passage with provenance.
    
    Every claim must be backed by evidence with:
    - Source document
    - Exact text
    - Location (page, section)
    - Relevance score
    - Support type (supports, contradicts, neutral)
    """
    
    text: str
    source: Publication
    
    # Location
    page: int | None
    section: str | None
    paragraph: int | None
    
    # Scoring
    relevance_score: float  # 0-1
    confidence: float  # 0-1
    support_type: Literal["supports", "contradicts", "neutral"]
    
    # Context
    context_before: str
    context_after: str
    
    def to_citation(self) -> str:
        """Generate inline citation."""
        return f"({self.source.first_author.family_name} et al., {self.source.year})"
```

### 5.3 Research Result Model

```python
@dataclass
class ResearchResult:
    """
    Complete research result with answer and evidence.
    """
    
    # The answer
    answer: str
    summary: str
    
    # Evidence
    evidence: list[Evidence]
    supporting_papers: list[Publication]
    
    # Quality metrics
    confidence: float
    evidence_quality: float
    contradictions: list[Contradiction]
    
    # Provenance
    query: str
    research_plan: ResearchPlan
    search_results: list[SearchResult]
    
    # Metadata
    total_papers_searched: int
    papers_with_fulltext: int
    processing_time: float
    llm_tokens_used: int
    estimated_cost: float
```

---

## Part 6: New Services

### 6.1 Synthesis Service (`src/litforge/services/synthesis.py`)

**Purpose**: Generate literature reviews and summaries

```python
class SynthesisService:
    """
    Synthesize findings across multiple papers.
    
    Capabilities:
    - Literature review generation
    - Comparative analysis
    - Gap identification
    - Trend analysis
    - Contradiction resolution
    """
    
    async def literature_review(
        self,
        topic: str,
        papers: list[Publication],
        *,
        style: Literal["narrative", "systematic", "scoping"] = "narrative",
        max_length: int = 2000,
    ) -> LiteratureReview:
        """Generate a literature review on a topic."""
    
    async def compare_papers(
        self,
        papers: list[Publication],
        aspects: list[str] | None = None,
    ) -> ComparisonResult:
        """Compare findings across papers."""
    
    async def identify_gaps(
        self,
        papers: list[Publication],
    ) -> list[ResearchGap]:
        """Identify research gaps in the literature."""
```

### 6.2 Concept Service (`src/litforge/services/concept.py`)

**Purpose**: Build and query concept networks

```python
class ConceptService:
    """
    Manage scientific concept extraction and organization.
    
    Capabilities:
    - Concept extraction from papers
    - Concept graph building
    - Concept clustering
    - Ontology mapping
    - Trend detection
    """
    
    async def extract_concepts(
        self,
        papers: list[Publication],
    ) -> list[Concept]:
        """Extract all concepts from papers."""
    
    async def build_concept_graph(
        self,
        papers: list[Publication],
    ) -> ConceptGraph:
        """Build concept relationship graph."""
    
    async def detect_trends(
        self,
        papers: list[Publication],
        time_window: str = "5y",
    ) -> list[Trend]:
        """Detect emerging trends in concepts."""
```

### 6.3 Export Service (`src/litforge/services/export.py`)

**Purpose**: Export to various formats

```python
class ExportService:
    """
    Export results to various formats.
    
    Formats:
    - BibTeX
    - RIS
    - EndNote XML
    - CSL-JSON
    - Markdown
    - HTML report
    - PDF report
    """
    
    def to_bibtex(self, papers: list[Publication]) -> str:
        """Export to BibTeX format."""
    
    def to_ris(self, papers: list[Publication]) -> str:
        """Export to RIS format."""
    
    def to_markdown_report(
        self,
        result: ResearchResult,
        *,
        include_evidence: bool = True,
        include_figures: bool = False,
    ) -> str:
        """Generate Markdown research report."""
```

---

## Part 7: Enhanced Features Not Previously Considered

### 7.1 ðŸ†• Query Understanding & Expansion

```python
class QueryProcessor:
    """
    Advanced query understanding and expansion.
    
    Features:
    - Entity recognition (chemicals, genes, diseases)
    - Synonym expansion (aspirin â†’ acetylsalicylic acid)
    - Ontology-aware expansion (CRISPR â†’ CRISPR-Cas9, CRISPR-Cas12a)
    - Query decomposition (complex â†’ sub-queries)
    - Intent classification (search, compare, summarize, explain)
    """
```

### 7.2 ðŸ†• Citation Intent Classification

```python
class CitationAnalyzer:
    """
    Analyze citation intent and context.
    
    Categories:
    - Background: General context
    - Method: Uses methodology from cited work
    - Result: Compares results
    - Support: Supports claims
    - Contrast: Contrasts with claims
    - Extension: Extends cited work
    """
```

### 7.3 ðŸ†• Quality & Reliability Scoring

```python
class QualityScorer:
    """
    Score paper and evidence quality.
    
    Metrics:
    - Venue impact factor
    - Author h-index
    - Citation velocity
    - Retraction status
    - Reproducibility indicators
    - Preprint vs peer-reviewed
    """
```

### 7.4 ðŸ†• Multi-Modal Support

```python
class MultiModalProcessor:
    """
    Process figures, tables, and equations.
    
    Features:
    - Figure caption extraction
    - Table parsing (to structured data)
    - Equation OCR (LaTeX)
    - Chemical structure recognition
    - Graph/chart data extraction
    """
```

### 7.5 ðŸ†• Personalization & Learning

```python
class UserProfile:
    """
    User-specific preferences and history.
    
    Features:
    - Search history
    - Favorite papers
    - Reading list
    - Concept interests
    - Citation style preference
    - Notification settings
    """
```

### 7.6 ðŸ†• Collaboration Features

```python
class CollaborationService:
    """
    Multi-user collaboration features.
    
    Features:
    - Shared collections
    - Annotations
    - Comments
    - Highlights
    - Export sharing
    """
```

### 7.7 ðŸ†• Monitoring & Analytics

```python
class AnalyticsService:
    """
    Usage analytics and monitoring.
    
    Metrics:
    - Query latency
    - Cache hit rate
    - API costs
    - Error rates
    - Popular queries
    - User engagement
    """
```

---

## Part 8: Revised Implementation Roadmap

### Phase 1: Core Excellence (Weeks 1-3) â­â­â­

**Goal**: Make the core search and retrieval world-class

| Task | File | Days | Priority |
|------|------|------|----------|
| Async-first architecture | `core/*.py` | 2 | â­â­â­ |
| OpenAlex client complete | `clients/openalex.py` | 1 | â­â­â­ |
| Semantic Scholar client | `clients/semantic_scholar.py` | 2 | â­â­â­ |
| Unpaywall client | `clients/unpaywall.py` | 1 | â­â­â­ |
| arXiv client | `clients/arxiv.py` | 1 | â­â­â­ |
| Multi-source search | `services/discovery.py` | 2 | â­â­â­ |
| Result deduplication | `services/discovery.py` | 1 | â­â­â­ |
| PDF waterfall retrieval | `services/retrieval.py` | 2 | â­â­â­ |
| Smart caching | `core/cache.py` | 1 | â­â­ |

**Deliverable**: `forge.search()` and `forge.get_fulltext()` work reliably

### Phase 2: Document Processing (Weeks 4-5) â­â­â­

**Goal**: State-of-the-art document understanding

| Task | File | Days | Priority |
|------|------|------|----------|
| PDF text extraction | `processors/pdf.py` | 2 | â­â­â­ |
| Section detection | `processors/sections.py` | 2 | â­â­â­ |
| Smart chunking | `processors/chunking.py` | 2 | â­â­â­ |
| Table extraction | `processors/tables.py` | 2 | â­â­ |
| Reference parsing | `processors/references.py` | 1 | â­â­ |

**Deliverable**: Full-text papers parsed into structured chunks

### Phase 3: RAG Pipeline (Weeks 6-7) â­â­â­

**Goal**: Evidence-based Q&A with citations

| Task | File | Days | Priority |
|------|------|------|----------|
| Embedding pipeline | `embedding/pipeline.py` | 2 | â­â­â­ |
| Hybrid retriever | `retrieval/hybrid.py` | 2 | â­â­â­ |
| Cross-encoder reranker | `retrieval/reranker.py` | 2 | â­â­â­ |
| Evidence extractor | `processors/evidence.py` | 2 | â­â­â­ |
| LLM synthesis | `llm/synthesis.py` | 2 | â­â­â­ |
| Citation grounding | `processors/citations.py` | 1 | â­â­â­ |

**Deliverable**: `forge.ask()` returns answers with evidence

### Phase 4: Research Agent (Weeks 8-9) â­â­â­

**Goal**: Autonomous multi-step research

| Task | File | Days | Priority |
|------|------|------|----------|
| Research planner | `agents/planner.py` | 2 | â­â­â­ |
| Research agent | `agents/research_agent.py` | 3 | â­â­â­ |
| Iterative refinement | `agents/refinement.py` | 2 | â­â­â­ |
| Contradiction detection | `processors/contradictions.py` | 2 | â­â­ |
| Confidence scoring | `processors/confidence.py` | 1 | â­â­ |

**Deliverable**: `forge.research()` conducts autonomous research

### Phase 5: Citation Networks (Weeks 10-11) â­â­

**Goal**: Advanced citation analysis

| Task | File | Days | Priority |
|------|------|------|----------|
| Citation graph building | `network/builder.py` | 2 | â­â­â­ |
| Influence metrics | `network/metrics.py` | 2 | â­â­ |
| Co-citation clustering | `network/clustering.py` | 2 | â­â­ |
| Trend detection | `network/trends.py` | 2 | â­â­ |
| Visualization export | `network/visualization.py` | 1 | â­â­ |

**Deliverable**: `forge.build_network()` with analysis

### Phase 6: Production Features (Weeks 12-14) â­â­

**Goal**: Production-ready system

| Task | File | Days | Priority |
|------|------|------|----------|
| Streaming support | `streaming/handler.py` | 2 | â­â­â­ |
| LLM router | `llm/router.py` | 2 | â­â­â­ |
| REST API | `api/rest.py` | 3 | â­â­ |
| CLI commands | `cli.py` | 2 | â­â­ |
| Export formats | `services/export.py` | 2 | â­â­ |
| Error handling | `core/errors.py` | 1 | â­â­ |
| Logging/metrics | `core/observability.py` | 1 | â­â­ |

**Deliverable**: Production-deployable system

---

## Part 9: New Directory Structure

```
src/litforge/
â”œâ”€â”€ __init__.py                 # Public API
â”œâ”€â”€ api.py                      # Simple API (sync)
â”œâ”€â”€ async_api.py                # NEW: Async API
â”œâ”€â”€ cli.py                      # CLI commands
â”œâ”€â”€ config.py                   # Configuration
â”‚
â”œâ”€â”€ agents/                     # NEW: Agentic components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                 # Base agent class
â”‚   â”œâ”€â”€ research_agent.py       # Main research agent
â”‚   â”œâ”€â”€ planner.py              # Research planner
â”‚   â””â”€â”€ refinement.py           # Answer refinement
â”‚
â”œâ”€â”€ api/                        # NEW: REST API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                  # FastAPI app
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”œâ”€â”€ papers.py
â”‚   â”‚   â”œâ”€â”€ qa.py
â”‚   â”‚   â””â”€â”€ research.py
â”‚   â””â”€â”€ models.py               # API models
â”‚
â”œâ”€â”€ clients/                    # External API clients
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ openalex.py             # ENHANCE
â”‚   â”œâ”€â”€ semantic_scholar.py     # IMPLEMENT
â”‚   â”œâ”€â”€ crossref.py             # ENHANCE
â”‚   â”œâ”€â”€ pubmed.py               # IMPLEMENT
â”‚   â”œâ”€â”€ arxiv.py                # IMPLEMENT
â”‚   â”œâ”€â”€ unpaywall.py            # IMPLEMENT
â”‚   â””â”€â”€ core_api.py             # NEW: CORE API
â”‚
â”œâ”€â”€ core/                       # Core functionality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ forge.py                # Main Forge class
â”‚   â”œâ”€â”€ cache.py                # NEW: Smart caching
â”‚   â”œâ”€â”€ errors.py               # NEW: Error types
â”‚   â””â”€â”€ observability.py        # NEW: Logging/metrics
â”‚
â”œâ”€â”€ embedding/                  # Embedding providers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ openai.py
â”‚   â”œâ”€â”€ sentence_transformers.py
â”‚   â””â”€â”€ cohere.py               # NEW
â”‚
â”œâ”€â”€ integrations/               # Framework integrations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crewai.py
â”‚   â”œâ”€â”€ langchain.py
â”‚   â”œâ”€â”€ langgraph.py
â”‚   â”œâ”€â”€ autogen.py              # NEW
â”‚   â””â”€â”€ llamaindex.py           # NEW
â”‚
â”œâ”€â”€ llm/                        # LLM providers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ router.py               # NEW: Smart routing
â”‚   â”œâ”€â”€ openai.py
â”‚   â”œâ”€â”€ anthropic.py            # NEW
â”‚   â”œâ”€â”€ groq.py                 # NEW
â”‚   â”œâ”€â”€ ollama.py               # NEW
â”‚   â””â”€â”€ synthesis.py            # NEW: Answer synthesis
â”‚
â”œâ”€â”€ mcp/                        # MCP server
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server.py
â”‚
â”œâ”€â”€ models/                     # Data models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ publication.py
â”‚   â”œâ”€â”€ document.py             # NEW: Rich document
â”‚   â”œâ”€â”€ evidence.py             # NEW: Evidence model
â”‚   â”œâ”€â”€ network.py
â”‚   â”œâ”€â”€ search.py
â”‚   â”œâ”€â”€ research.py             # NEW: Research result
â”‚   â””â”€â”€ concepts.py             # NEW: Concept model
â”‚
â”œâ”€â”€ network/                    # NEW: Citation networks
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ builder.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ clustering.py
â”‚   â”œâ”€â”€ trends.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ processors/                 # NEW: Document processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf.py                  # PDF extraction
â”‚   â”œâ”€â”€ sections.py             # Section detection
â”‚   â”œâ”€â”€ chunking.py             # Smart chunking
â”‚   â”œâ”€â”€ tables.py               # Table extraction
â”‚   â”œâ”€â”€ references.py           # Reference parsing
â”‚   â”œâ”€â”€ evidence.py             # Evidence extraction
â”‚   â”œâ”€â”€ concepts.py             # Concept extraction
â”‚   â”œâ”€â”€ citations.py            # Citation grounding
â”‚   â”œâ”€â”€ contradictions.py       # Contradiction detection
â”‚   â””â”€â”€ confidence.py           # Confidence scoring
â”‚
â”œâ”€â”€ retrieval/                  # NEW: Advanced retrieval
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hybrid.py               # Hybrid search
â”‚   â”œâ”€â”€ reranker.py             # Cross-encoder
â”‚   â””â”€â”€ query.py                # Query processing
â”‚
â”œâ”€â”€ services/                   # Business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ discovery.py            # ENHANCE
â”‚   â”œâ”€â”€ retrieval.py            # IMPLEMENT
â”‚   â”œâ”€â”€ citation.py             # IMPLEMENT
â”‚   â”œâ”€â”€ knowledge.py            # IMPLEMENT
â”‚   â”œâ”€â”€ qa.py                   # IMPLEMENT
â”‚   â”œâ”€â”€ synthesis.py            # NEW
â”‚   â”œâ”€â”€ concept.py              # NEW
â”‚   â””â”€â”€ export.py               # NEW
â”‚
â”œâ”€â”€ stores/                     # Vector stores
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ chromadb.py
â”‚   â”œâ”€â”€ faiss.py
â”‚   â”œâ”€â”€ qdrant.py
â”‚   â””â”€â”€ pgvector.py             # NEW
â”‚
â”œâ”€â”€ streaming/                  # NEW: Streaming support
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ handler.py
â”‚   â””â”€â”€ events.py
â”‚
â””â”€â”€ ui/                         # Web interfaces
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ app.py
    â””â”€â”€ chat.py
```

---

## Part 10: Dependencies to Add

```toml
[project]
dependencies = [
    # Existing
    "httpx>=0.27",
    "pydantic>=2.0",
    "chromadb>=0.4",
    
    # API Clients
    "pyalex>=0.13",              # OpenAlex
    "semanticscholar>=0.8",       # Semantic Scholar
    "arxiv>=2.1",                 # arXiv
    "biopython>=1.83",            # PubMed via Entrez
    
    # PDF Processing
    "pypdf>=4.0",                 # Basic PDF
    "pymupdf>=1.24",              # Advanced PDF
    "pdfplumber>=0.11",           # Table extraction
    
    # Embeddings
    "sentence-transformers>=2.7", # Local embeddings
    "openai>=1.40",               # OpenAI embeddings
    
    # RAG
    "rank-bm25>=0.2",             # BM25 sparse retrieval
    "faiss-cpu>=1.8",             # FAISS vector search
    
    # LLM
    "groq>=0.9",                  # Groq (free tier)
    "anthropic>=0.34",            # Claude
    "ollama>=0.3",                # Local LLMs
    
    # Graphs
    "networkx>=3.3",              # Citation networks
    "pyvis>=0.3",                 # Visualization
    
    # API
    "fastapi>=0.111",             # REST API
    "uvicorn>=0.30",              # ASGI server
    
    # Utilities
    "tenacity>=8.5",              # Retry logic
    "cachetools>=5.5",            # Caching
    "structlog>=24.4",            # Structured logging
]
```

---

## Part 11: Success Metrics

### Quality Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| Search relevance | >90% precision@10 | Human evaluation |
| PDF retrieval | >70% OA success | Automated testing |
| Evidence accuracy | >95% correct citations | LLM evaluation |
| Answer quality | Match PaperQA2 | DeepResearchGym |
| Hallucination rate | <5% | LLM-as-judge |

### Performance Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| Search latency | <2s | p95 |
| PDF retrieval | <10s | p95 |
| RAG Q&A | <15s | p95 |
| Research (deep) | <120s | p95 |
| Streaming TTFB | <500ms | p95 |

### Cost Metrics

| Operation | Target Cost | Breakdown |
|-----------|-------------|-----------|
| Search | $0.00 | Free APIs |
| PDF retrieval | $0.00 | Free sources |
| Simple Q&A | $0.01 | Groq free tier |
| Deep research | $0.10 | 10 LLM calls |

---

## Conclusion

This enhanced plan transforms LitForge from a basic search library into a **state-of-the-art research agent platform** that can:

1. **Search** across 6+ sources with intelligent fusion
2. **Retrieve** PDFs with 70%+ success rate
3. **Process** documents into structured, searchable knowledge
4. **Answer** questions with evidence-grounded citations
5. **Research** autonomously with multi-step reasoning
6. **Analyze** citation networks and detect trends
7. **Integrate** seamlessly with multi-agent systems

The 14-week roadmap prioritizes:
- **Weeks 1-7**: Core excellence (search, retrieval, RAG)
- **Weeks 8-11**: Advanced features (agents, networks)
- **Weeks 12-14**: Production readiness

**Recommended Immediate Actions**:
1. Implement Semantic Scholar client (best citation data)
2. Implement Unpaywall client (unlocks PDFs)
3. Add async architecture (enables parallel operations)
4. Build hybrid retrieval (better search quality)

---

*Document Version: 2.0*  
*Last Updated: January 2025*
