# LitForge Implementation Master Plan

**Version**: 1.0  
**Created**: January 14, 2025  
**Status**: üöÄ Active Development

---

## Pre-Implementation Audit Summary

### Existing Code Analysis (9,462 lines total)

| Component | Lines | Status | Assessment |
|-----------|-------|--------|------------|
| **api.py** | 385 | ‚úÖ Working | Simple API functional, uses OpenAlex directly |
| **core/forge.py** | 549 | ‚ö†Ô∏è Structure | Good structure, needs to connect to services |
| **clients/openalex.py** | 232 | ‚úÖ Implemented | Functional, needs minor enhancements |
| **clients/semantic_scholar.py** | 268 | ‚úÖ Implemented | Functional, needs testing |
| **clients/pubmed.py** | 312 | ‚úÖ Implemented | Functional, uses E-utilities |
| **clients/arxiv.py** | 222 | ‚úÖ Implemented | Functional, XML parsing |
| **clients/crossref.py** | 204 | ‚úÖ Implemented | Functional |
| **clients/unpaywall.py** | 85 | ‚úÖ Implemented | Functional, needs batch support |
| **services/discovery.py** | 271 | ‚ö†Ô∏è Partial | Structure exists, needs multi-source |
| **services/retrieval.py** | 235 | ‚ö†Ô∏è Partial | PDF download exists, needs text extraction |
| **services/knowledge.py** | 311 | ‚ö†Ô∏è Partial | Indexing exists, needs chunking |
| **services/qa.py** | 283 | ‚ö†Ô∏è Partial | RAG structure, needs LLM connection |
| **services/citation.py** | 366 | ‚ö†Ô∏è Partial | Network building exists, needs NetworkX |
| **stores/chromadb.py** | 195 | ‚úÖ Implemented | Fully functional |
| **stores/faiss.py** | 373 | ‚úÖ Implemented | Functional |
| **stores/qdrant.py** | 268 | ‚úÖ Implemented | Functional |
| **embedding/sentence_transformers.py** | 91 | ‚úÖ Implemented | Local embeddings work |
| **embedding/openai.py** | 111 | ‚úÖ Implemented | OpenAI embeddings work |
| **llm/openai.py** | 89 | ‚úÖ Implemented | Basic OpenAI LLM |
| **ui/app.py** | 557 | ‚úÖ Working | Form UI works |
| **ui/chat.py** | 432 | ‚úÖ Working | Chat UI works |
| **mcp/server.py** | 145 | ‚úÖ Working | MCP integration works |
| **integrations/** | 1097 | ‚úÖ Working | CrewAI, LangChain, LangGraph |

### Key Finding: More Complete Than Expected

The codebase has **substantial implementations** already. The main gaps are:
1. **Missing PDF text extraction** (pypdf/pymupdf not integrated)
2. **Missing LLM providers** (only OpenAI, need Groq/Anthropic/Ollama)
3. **Forge class not wired to services** properly
4. **Missing async support** throughout
5. **Missing advanced features** (reranking, hybrid search, agents)

---

## Implementation Phases - Detailed Breakdown

### Legend
- üî¥ Not Started
- üü° In Progress
- üü¢ Complete
- ‚è≠Ô∏è Skipped (already exists)

---

## Phase 1: Core Excellence (Weeks 1-3)

### Goal: Make search, retrieval, and Forge class work reliably

### 1.1 Connect Forge Class to Working Services üî¥

**File**: `src/litforge/core/forge.py`

| Task | Status | Notes |
|------|--------|-------|
| Wire `search()` to discovery service | üî¥ | Currently not calling service properly |
| Wire `lookup()` to clients | üî¥ | Need DOI resolution |
| Wire `get_paper()` to return Publication | üî¥ | |
| Wire `get_citations()` to clients | üî¥ | Need S2/OpenAlex |
| Wire `get_references()` to clients | üî¥ | |
| Add proper error handling | üî¥ | |
| Add logging | üî¥ | |

### 1.2 Enhance Discovery Service üî¥

**File**: `src/litforge/services/discovery.py`

| Task | Status | Notes |
|------|--------|-------|
| Parallel multi-source search | üî¥ | Use asyncio.gather |
| Result deduplication by DOI | üî¥ | Merge same papers from diff sources |
| Source attribution | üî¥ | Track which source found each paper |
| Relevance scoring | üî¥ | Combine scores from sources |
| Rate limit handling | üî¥ | Respect API limits |

### 1.3 Add Async Architecture üî¥

**Files**: Multiple

| Task | Status | Notes |
|------|--------|-------|
| Create `async_api.py` | üî¥ | Async versions of simple API |
| Add async to base client | üî¥ | `clients/base.py` |
| Add async to all clients | üî¥ | OpenAlex, S2, etc |
| Add async to services | üî¥ | Discovery, retrieval |
| Keep sync wrappers | ‚è≠Ô∏è | Already have sync API |

### 1.4 Test & Validate Clients üî¥

| Client | Status | Test Query |
|--------|--------|------------|
| OpenAlex | üî¥ | `forge.search("CRISPR", sources=["openalex"])` |
| Semantic Scholar | üî¥ | `forge.search("transformer", sources=["semantic_scholar"])` |
| PubMed | üî¥ | `forge.search("cancer", sources=["pubmed"])` |
| arXiv | üî¥ | `forge.search("neural network", sources=["arxiv"])` |
| CrossRef | üî¥ | `forge.lookup("10.1038/nature12373")` |
| Unpaywall | üî¥ | `forge.get_open_access("10.1038/nature12373")` |

---

## Phase 2: PDF Processing (Weeks 4-5)

### Goal: Extract text from PDFs reliably

### 2.1 Add PDF Extraction üî¥

**New File**: `src/litforge/processors/pdf.py`

| Task | Status | Notes |
|------|--------|-------|
| Create PDFExtractor class | üî¥ | |
| pypdf extraction (simple) | üî¥ | Fallback method |
| pymupdf extraction (advanced) | üî¥ | Better quality |
| Fallback chain | üî¥ | Try pymupdf ‚Üí pypdf |
| Handle encrypted PDFs | üî¥ | Skip gracefully |
| Handle scanned PDFs | üî¥ | Detect and warn |

### 2.2 Add Section Detection üî¥

**New File**: `src/litforge/processors/sections.py`

| Task | Status | Notes |
|------|--------|-------|
| Create SectionDetector class | üî¥ | |
| Detect Abstract | üî¥ | Pattern matching |
| Detect Introduction | üî¥ | |
| Detect Methods | üî¥ | |
| Detect Results | üî¥ | |
| Detect Discussion | üî¥ | |
| Detect References | üî¥ | |
| Handle non-standard formats | üî¥ | Best effort |

### 2.3 Add Smart Chunking üî¥

**New File**: `src/litforge/processors/chunking.py`

| Task | Status | Notes |
|------|--------|-------|
| Create TextChunker class | üî¥ | |
| Sentence-based chunking | üî¥ | Respect sentence boundaries |
| Paragraph-based chunking | üî¥ | |
| Section-aware chunking | üî¥ | Don't split sections |
| Configurable overlap | üî¥ | 10-20% overlap |
| Token counting | üî¥ | For LLM context limits |

### 2.4 Connect to Retrieval Service üî¥

**File**: `src/litforge/services/retrieval.py`

| Task | Status | Notes |
|------|--------|-------|
| Integrate PDFExtractor | üî¥ | Call from retrieve() |
| Integrate SectionDetector | üî¥ | Optional parsing |
| Add text caching | üî¥ | Cache extracted text |
| Add `retrieve_text()` method | üî¥ | Return structured text |
| Add batch processing | üî¥ | Multiple PDFs |

---

## Phase 3: RAG Pipeline (Weeks 6-7)

### Goal: Answer questions with citations

### 3.1 Add More LLM Providers üî¥

**New Files**: `src/litforge/llm/`

| Provider | File | Status | Notes |
|----------|------|--------|-------|
| Groq | `groq.py` | üî¥ | Free tier, fast |
| Anthropic | `anthropic.py` | üî¥ | Claude models |
| Ollama | `ollama.py` | üî¥ | Local LLMs |
| Router | `router.py` | üî¥ | Smart routing with fallback |

### 3.2 Add Hybrid Retrieval üî¥

**New File**: `src/litforge/retrieval/hybrid.py`

| Task | Status | Notes |
|------|--------|-------|
| BM25 sparse retrieval | üî¥ | Using rank_bm25 |
| Dense retrieval | ‚è≠Ô∏è | Already have via stores |
| Hybrid combination | üî¥ | RRF or weighted |
| Configurable weights | üî¥ | dense_weight, sparse_weight |

### 3.3 Add Cross-Encoder Reranking üî¥

**New File**: `src/litforge/retrieval/reranker.py`

| Task | Status | Notes |
|------|--------|-------|
| CrossEncoderReranker class | üî¥ | |
| Use ms-marco-MiniLM | üî¥ | Default model |
| Batch reranking | üî¥ | Efficient processing |
| Score normalization | üî¥ | 0-1 range |

### 3.4 Add Evidence Extraction üî¥

**New File**: `src/litforge/processors/evidence.py`

| Task | Status | Notes |
|------|--------|-------|
| EvidenceExtractor class | üî¥ | |
| Extract supporting passages | üî¥ | |
| Score relevance | üî¥ | |
| Add citation context | üî¥ | Before/after text |
| Track provenance | üî¥ | Source, page, section |

### 3.5 Connect QA Service üî¥

**File**: `src/litforge/services/qa.py`

| Task | Status | Notes |
|------|--------|-------|
| Use LLM router | üî¥ | Not just OpenAI |
| Integrate hybrid retrieval | üî¥ | Better context |
| Integrate reranker | üî¥ | Better top-k |
| Add evidence in response | üî¥ | With citations |
| Add confidence scoring | üî¥ | Based on evidence |
| Add streaming support | üî¥ | For long answers |

---

## Phase 4: Research Agent (Weeks 8-9)

### Goal: Autonomous multi-step research

### 4.1 Create Research Agent üî¥

**New File**: `src/litforge/agents/research_agent.py`

| Task | Status | Notes |
|------|--------|-------|
| ResearchAgent class | üî¥ | |
| Plan generation | üî¥ | Break query into steps |
| Step execution | üî¥ | Search ‚Üí Retrieve ‚Üí Analyze |
| Iterative refinement | üî¥ | Improve answer |
| Progress tracking | üî¥ | For streaming UI |

### 4.2 Add Research Planner üî¥

**New File**: `src/litforge/agents/planner.py`

| Task | Status | Notes |
|------|--------|-------|
| ResearchPlanner class | üî¥ | |
| Query decomposition | üî¥ | Complex ‚Üí sub-queries |
| Dependency detection | üî¥ | Order matters |
| Resource estimation | üî¥ | Papers needed |

### 4.3 Add Contradiction Detection üî¥

**New File**: `src/litforge/processors/contradictions.py`

| Task | Status | Notes |
|------|--------|-------|
| ContradictionDetector class | üî¥ | |
| Compare evidence pairs | üî¥ | |
| Classify relationship | üî¥ | Support/contradict/neutral |
| Report conflicts | üî¥ | In research result |

---

## Phase 5: Citation Networks (Weeks 10-11)

### Goal: Advanced citation analysis

### 5.1 Integrate NetworkX üî¥

**File**: `src/litforge/services/citation.py`

| Task | Status | Notes |
|------|--------|-------|
| NetworkX graph building | üî¥ | Replace manual graph |
| PageRank centrality | üî¥ | Proper algorithm |
| Betweenness centrality | üî¥ | |
| Community detection | üî¥ | Louvain algorithm |

### 5.2 Add Network Analysis üî¥

**New File**: `src/litforge/network/metrics.py`

| Task | Status | Notes |
|------|--------|-------|
| Influence metrics | üî¥ | |
| Co-citation analysis | üî¥ | |
| Bibliographic coupling | üî¥ | |
| Temporal analysis | üî¥ | Trends over time |

### 5.3 Add Visualization Export üî¥

**New File**: `src/litforge/network/visualization.py`

| Task | Status | Notes |
|------|--------|-------|
| Export to JSON (D3) | üî¥ | |
| Export to Gephi | üî¥ | .gexf format |
| Generate pyvis HTML | üî¥ | Interactive |

---

## Phase 6: Production Features (Weeks 12-14)

### Goal: Production-ready system

### 6.1 Add Streaming Support üî¥

**New File**: `src/litforge/streaming/handler.py`

| Task | Status | Notes |
|------|--------|-------|
| StreamingHandler class | üî¥ | |
| SSE support | üî¥ | Server-sent events |
| Event types | üî¥ | Search, retrieve, answer |
| Progress updates | üî¥ | For UI |

### 6.2 Add REST API üî¥

**New Files**: `src/litforge/api/`

| Task | Status | Notes |
|------|--------|-------|
| FastAPI app | üî¥ | `api/app.py` |
| Search endpoint | üî¥ | `POST /search` |
| Paper endpoint | üî¥ | `GET /paper/{doi}` |
| Ask endpoint | üî¥ | `POST /ask` |
| Research endpoint | üî¥ | `POST /research` |
| OpenAPI docs | üî¥ | Auto-generated |

### 6.3 Enhance CLI üî¥

**File**: `src/litforge/cli.py`

| Task | Status | Notes |
|------|--------|-------|
| `litforge search` | üî¥ | Working command |
| `litforge ask` | üî¥ | RAG Q&A |
| `litforge download` | üî¥ | Get PDFs |
| `litforge serve` | üî¥ | Start REST API |
| Progress bars | üî¥ | Rich/tqdm |

### 6.4 Add Export Formats üî¥

**New File**: `src/litforge/services/export.py`

| Task | Status | Notes |
|------|--------|-------|
| BibTeX export | üî¥ | |
| RIS export | üî¥ | |
| Markdown report | üî¥ | |
| JSON export | üî¥ | |

### 6.5 Error Handling & Observability üî¥

**New Files**: `src/litforge/core/`

| Task | Status | Notes |
|------|--------|-------|
| Custom exceptions | üî¥ | `errors.py` |
| Structured logging | üî¥ | `observability.py` |
| Metrics collection | üî¥ | Optional |
| Rate limit tracking | üî¥ | Per API |

---

## New Files to Create

```
src/litforge/
‚îú‚îÄ‚îÄ async_api.py                    # Phase 1
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 4
‚îÇ   ‚îú‚îÄ‚îÄ research_agent.py           # Phase 4
‚îÇ   ‚îî‚îÄ‚îÄ planner.py                  # Phase 4
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 6
‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # Phase 6
‚îÇ   ‚îî‚îÄ‚îÄ routes/                     # Phase 6
‚îÇ       ‚îú‚îÄ‚îÄ search.py
‚îÇ       ‚îú‚îÄ‚îÄ papers.py
‚îÇ       ‚îî‚îÄ‚îÄ qa.py
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îú‚îÄ‚îÄ groq.py                     # Phase 3
‚îÇ   ‚îú‚îÄ‚îÄ anthropic.py                # Phase 3
‚îÇ   ‚îú‚îÄ‚îÄ ollama.py                   # Phase 3
‚îÇ   ‚îî‚îÄ‚îÄ router.py                   # Phase 3
‚îú‚îÄ‚îÄ network/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 5
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                  # Phase 5
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py            # Phase 5
‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 2
‚îÇ   ‚îú‚îÄ‚îÄ pdf.py                      # Phase 2
‚îÇ   ‚îú‚îÄ‚îÄ sections.py                 # Phase 2
‚îÇ   ‚îú‚îÄ‚îÄ chunking.py                 # Phase 2
‚îÇ   ‚îú‚îÄ‚îÄ evidence.py                 # Phase 3
‚îÇ   ‚îî‚îÄ‚îÄ contradictions.py           # Phase 4
‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 3
‚îÇ   ‚îú‚îÄ‚îÄ hybrid.py                   # Phase 3
‚îÇ   ‚îî‚îÄ‚îÄ reranker.py                 # Phase 3
‚îú‚îÄ‚îÄ streaming/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Phase 6
‚îÇ   ‚îî‚îÄ‚îÄ handler.py                  # Phase 6
‚îî‚îÄ‚îÄ core/
    ‚îú‚îÄ‚îÄ errors.py                   # Phase 6
    ‚îî‚îÄ‚îÄ observability.py            # Phase 6
```

## Files to Modify

```
src/litforge/
‚îú‚îÄ‚îÄ core/forge.py                   # Phase 1 - Wire to services
‚îú‚îÄ‚îÄ services/discovery.py           # Phase 1 - Multi-source
‚îú‚îÄ‚îÄ services/retrieval.py           # Phase 2 - PDF extraction
‚îú‚îÄ‚îÄ services/knowledge.py           # Phase 3 - Better chunking
‚îú‚îÄ‚îÄ services/qa.py                  # Phase 3 - Full RAG
‚îú‚îÄ‚îÄ services/citation.py            # Phase 5 - NetworkX
‚îú‚îÄ‚îÄ clients/base.py                 # Phase 1 - Async support
‚îú‚îÄ‚îÄ config.py                       # Phase 1 - New providers
‚îî‚îÄ‚îÄ cli.py                          # Phase 6 - Working commands
```

---

## Dependencies to Add

```toml
[project.dependencies]
# PDF Processing (Phase 2)
pypdf = ">=4.0"
pymupdf = ">=1.24"

# RAG (Phase 3)
rank-bm25 = ">=0.2"
sentence-transformers = ">=2.7"  # May already exist

# LLM Providers (Phase 3)
groq = ">=0.9"
anthropic = ">=0.34"
ollama = ">=0.3"

# Networks (Phase 5)
networkx = ">=3.3"
pyvis = ">=0.3"

# REST API (Phase 6)
fastapi = ">=0.111"
uvicorn = ">=0.30"

# Utilities
tenacity = ">=8.5"  # Retry logic
structlog = ">=24.4"  # Logging
rich = ">=13.7"  # CLI
```

---

## Testing Checkpoints

### After Phase 1
```python
from litforge import Forge
forge = Forge()

# Multi-source search
papers = forge.search("CRISPR", sources=["openalex", "semantic_scholar"])
assert len(papers) > 0
print(f"Found {len(papers)} papers from {set(p.sources[0] for p in papers)}")

# DOI lookup
paper = forge.lookup("10.1126/science.aax5077")
assert paper is not None
```

### After Phase 2
```python
# PDF retrieval and extraction
paper = forge.lookup("10.1126/science.aax5077")
text = forge.get_fulltext(paper)
assert text is not None
assert len(text) > 1000
print(f"Extracted {len(text)} characters")
```

### After Phase 3
```python
# RAG Q&A
papers = forge.search("CRISPR delivery", limit=10)
forge.index(papers)
answer = forge.ask("What are the main CRISPR delivery mechanisms?")
assert answer.text
assert len(answer.evidence) > 0
print(answer.text)
```

### After Phase 4
```python
# Research agent
result = await forge.research(
    "What are the latest advances in mRNA vaccines?",
    depth="standard"
)
assert result.answer
assert result.confidence > 0.5
print(f"Answer with {len(result.evidence)} sources")
```

### After Phase 5
```python
# Citation network
network = forge.build_network(
    ["10.1126/science.aax5077"],
    depth=2
)
assert len(network.nodes) > 10
key_papers = network.most_influential(5)
print(f"Key papers: {[p.title[:50] for p in key_papers]}")
```

### After Phase 6
```bash
# CLI
litforge search "machine learning drug discovery" --limit 10
litforge ask "What ML methods are used for drug discovery?"
litforge serve --port 8000
```

---

## Progress Tracking

Use this checklist to track progress. Update status as you complete each task.

### Phase 1 Progress
- [ ] 1.1 Connect Forge class
- [ ] 1.2 Enhance Discovery service
- [ ] 1.3 Add async architecture
- [ ] 1.4 Test all clients

### Phase 2 Progress
- [ ] 2.1 PDF extraction
- [ ] 2.2 Section detection
- [ ] 2.3 Smart chunking
- [ ] 2.4 Connect to retrieval

### Phase 3 Progress
- [ ] 3.1 LLM providers (Groq, Anthropic, Ollama)
- [ ] 3.2 Hybrid retrieval
- [ ] 3.3 Cross-encoder reranking
- [ ] 3.4 Evidence extraction
- [ ] 3.5 Connect QA service

### Phase 4 Progress
- [ ] 4.1 Research agent
- [ ] 4.2 Research planner
- [ ] 4.3 Contradiction detection

### Phase 5 Progress
- [ ] 5.1 NetworkX integration
- [ ] 5.2 Network analysis
- [ ] 5.3 Visualization export

### Phase 6 Progress
- [ ] 6.1 Streaming support
- [ ] 6.2 REST API
- [ ] 6.3 CLI enhancement
- [ ] 6.4 Export formats
- [ ] 6.5 Error handling

---

## Notes on Avoiding Duplication

### Already Exists - DO NOT RECREATE:
1. ‚úÖ Vector stores (ChromaDB, FAISS, Qdrant) - fully working
2. ‚úÖ Embedding providers (OpenAI, sentence-transformers) - working
3. ‚úÖ OpenAI LLM provider - working
4. ‚úÖ All clients (OpenAlex, S2, PubMed, arXiv, CrossRef, Unpaywall) - implemented
5. ‚úÖ MCP server - working
6. ‚úÖ Framework integrations - working
7. ‚úÖ Web UI (form + chat) - working
8. ‚úÖ Publication/Author models - complete

### Needs Enhancement - MODIFY EXISTING:
1. ‚ö†Ô∏è Forge class - wire to services
2. ‚ö†Ô∏è Discovery service - add multi-source
3. ‚ö†Ô∏è Retrieval service - add PDF extraction
4. ‚ö†Ô∏è Knowledge service - add better chunking
5. ‚ö†Ô∏è QA service - add LLM router
6. ‚ö†Ô∏è Citation service - add NetworkX
7. ‚ö†Ô∏è CLI - add working commands
8. ‚ö†Ô∏è Config - add new provider options

### Needs Creation - NEW FILES:
1. üî¥ PDF processors (pdf.py, sections.py, chunking.py)
2. üî¥ LLM providers (groq.py, anthropic.py, ollama.py, router.py)
3. üî¥ Retrieval enhancements (hybrid.py, reranker.py)
4. üî¥ Evidence processor
5. üî¥ Research agent
6. üî¥ Network analysis
7. üî¥ REST API
8. üî¥ Streaming

---

*Ready to begin implementation. Update this document as progress is made.*
